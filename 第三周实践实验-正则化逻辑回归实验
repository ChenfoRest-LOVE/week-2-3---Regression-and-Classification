import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from scipy import optimize

def load_data(file_path):
    data = pd.read_csv(file_path, header=None)
    X = data.iloc[:, :-1].values
    y = data.iloc[:, -1].values
    return X, y

def plot_data(X, y):
    pos = y == 1
    neg = y == 0
    plt.figure(figsize=(10, 6))
    plt.plot(X[pos, 0], X[pos, 1], 'k+', linewidth=2, markersize=7, label='y=1')
    plt.plot(X[neg, 0], X[neg, 1], 'ko', markerfacecolor='y', markersize=7, label='y=0')
    plt.xlabel('Feature 1')
    plt.ylabel('Feature 2')
    plt.legend()
    plt.grid(True)
    plt.title('Scatter plot of training data')

def feature_mapping(X1, X2, degree=6):
    out = np.ones((X1.shape[0], 1))
    for i in range(1, degree + 1):
        for j in range(i + 1):
            out = np.hstack((out, (X1**(i-j) * X2**j).reshape(-1, 1)))
    return out

def sigmoid(z):
    return 1 / (1 + np.exp(-z))

def compute_cost_reg(theta, X, y, lambda_):
    m = len(y)
    h = sigmoid(X @ theta)
    cost = -1/m * (y.T @ np.log(h) + (1-y).T @ np.log(1-h))
    cost += lambda_/(2*m) * np.sum(theta[1:]**2)
    return cost

def compute_gradient_reg(theta, X, y, lambda_):
    m = len(y)
    h = sigmoid(X @ theta)
    grad = 1/m * X.T @ (h - y)
    grad[1:] += lambda_/m * theta[1:]
    return grad

def predict(theta, X):
    return sigmoid(X @ theta) >= 0.5

def plot_decision_boundary(theta, X, y, degree=1):
    u = np.linspace(-1, 1.5, 50)
    v = np.linspace(-1, 1.5, 50)
    z = np.zeros((len(u), len(v)))
    for i in range(len(u)):
        for j in range(len(v)):
            mapped_features = feature_mapping(np.array([u[i]]), np.array([v[j]]), degree)
            z[i, j] = mapped_features @ theta
    plot_data(X, y)
    plt.contour(u, v, z.T, levels=[0], linewidth=2)
    plt.title(f'Decision boundary with polynomial features (degree {degree})')

def main():
    X, y = load_data('ex2data2.csv')
    plot_data(X, y)
    plt.show()
    
    X_mapped = feature_mapping(X[:, 0], X[:, 1], degree=6)
    initial_theta = np.zeros(X_mapped.shape[1])
    lambda_ = 1
    initial_cost = compute_cost_reg(initial_theta, X_mapped, y, lambda_)
    print(f"Initial cost: {initial_cost}")
    
    result = optimize.minimize(
        fun=compute_cost_reg,
        x0=initial_theta,
        args=(X_mapped, y, lambda_),
        method='BFGS',
        jac=compute_gradient_reg,
        options={'maxiter': 400}
    )
    
    theta_opt = result.x
    print(f"Final cost: {result.fun}")
    
    p = predict(theta_opt, X_mapped)
    accuracy = np.mean(p == y) * 100
    print(f"Train accuracy: {accuracy}%")
    
    plt.figure(figsize=(10, 6))
    plot_decision_boundary(theta_opt, X, y, degree=6)
    plt.show()
    
    lambda_values = [0, 1, 10, 100]
    plt.figure(figsize=(16, 12))
    
    for i, lambda_val in enumerate(lambda_values):
        result = optimize.minimize(
            fun=compute_cost_reg,
            x0=initial_theta,
            args=(X_mapped, y, lambda_val),
            method='BFGS',
            jac=compute_gradient_reg,
            options={'maxiter': 400}
        )
        
        theta = result.x
        plt.subplot(2, 2, i+1)
        plot_decision_boundary(theta, X, y, degree=6)
        plt.title(f'Lambda = {lambda_val}')
        
        p = predict(theta, X_mapped)
        accuracy = np.mean(p == y) * 100
        plt.xlabel(f'Train accuracy: {accuracy:.2f}%')
    
    plt.tight_layout()
    plt.show()
    
    print("\n正则化参数对模型性能的影响：")
    print("----------------------------")
    print("Lambda\tTrain Accuracy\tDescription")
    print("----------------------------")
    
    for lambda_val in [0, 0.01, 0.1, 1, 10, 100]:
        result = optimize.minimize(
            fun=compute_cost_reg,
            x0=initial_theta,
            args=(X_mapped, y, lambda_val),
            method='BFGS',
            jac=compute_gradient_reg,
            options={'maxiter': 400}
        )
        
        theta = result.x
        p = predict(theta, X_mapped)
        accuracy = np.mean(p == y) * 100
        
        description = ""
        if lambda_val == 0:
            description = "过拟合 (no regularization)"
        elif lambda_val < 1:
            description = "轻微正则化"
        elif lambda_val == 1:
            description = "适当正则化"
        else:
            description = "过度正则化，可能欠拟合"
            
        print(f"{lambda_val}\t{accuracy:.2f}%\t\t{description}")
        
if __name__ == "__main__":
    main()
